{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071e592e-1dcc-4ed6-afca-47ada7d01b6f",
   "metadata": {},
   "source": [
    "### Types of AI Agents\n",
    "\n",
    "#### Simple reflex agent\n",
    "\n",
    "<img src='./simple-reflex-agent.png' />\n",
    "\n",
    "- The Simple reflex agents are the simplest agents. These agents take decisions on the basis of the current percepts and ignore the rest of the percept history.\n",
    "- These agents only succeed in the fully observable environment.\n",
    "- The Simple reflex agent does not consider any part of percepts history during their decision and action process.\n",
    "- The Simple reflex agent works on Condition-action rule, which means it maps the current state to action. Such as a Room Cleaner agent, it works only if there is dirt in the room.\n",
    "- Problems for the simple reflex agent design approach:\n",
    "    - They have very limited intelligence\n",
    "    - They do not have knowledge of non-perceptual parts of the current state\n",
    "    - Mostly too big to generate and to store.\n",
    "    - Not adaptive to changes in the environment.\n",
    "\n",
    "#### Model-based reflex agent\n",
    "\n",
    "<img src=\"./model-based-reflex-agent.png\"  />\n",
    "\n",
    "- The Model-based agent can work in a partially observable environment, and track the situation.\n",
    "- A model-based agent has two important factors:\n",
    "    - Model: It is knowledge about \"how things happen in the world,\" so it is called a Model-based agent.\n",
    "    - Internal State: It is a representation of the current state based on percept history.\n",
    "- These agents have the model, \"which is knowledge of the world\" and based on the model they perform actions.\n",
    "- Updating the agent state requires information about:\n",
    "    - How the world evolves\n",
    "    - How the agent's action affects the world.\n",
    "    \n",
    "#### Goal-based agents\n",
    "\n",
    "<img src=\"./goal-based-agent.png\"  />\n",
    "\n",
    "- The knowledge of the current state environment is not always sufficient to decide for an agent to what to do.\n",
    "- The agent needs to know its goal which describes desirable situations.\n",
    "- Goal-based agents expand the capabilities of the model-based agent by having the \"goal\" information.\n",
    "- They choose an action, so that they can achieve the goal.\n",
    "- These agents may have to consider a long sequence of possible actions before deciding whether the goal is achieved or not. Such considerations of different scenario are - called searching and planning, which makes an agent proactive.\n",
    "\n",
    "#### Utility-based agents\n",
    "\n",
    "<img src=\"./utility-based-agent.png\"  />\n",
    "\n",
    "- These agents are similar to the goal-based agent but provide an extra component of utility measurement which makes them different by providing a measure of success at a - given state.\n",
    "- Utility-based agent act based not only goals but also the best way to achieve the goal.\n",
    "- The Utility-based agent is useful when there are multiple possible alternatives, and an agent has to choose in order to perform the best action.\n",
    "- The utility function maps each state to a real number to check how efficiently each action achieves the goals.\n",
    "\n",
    "#### Learning agents\n",
    "\n",
    "<img src=\"./learning-agent.png\"  />\n",
    "\n",
    "- A learning agent in AI is the type of agent which can learn from its past experiences, or it has learning capabilities.\n",
    "- It starts to act with basic knowledge and then able to act and adapt automatically through learning.\n",
    "- A learning agent has mainly four conceptual components, which are:\n",
    "    - Learning element: It is responsible for making improvements by learning from environment\n",
    "    - Critic: Learning element takes feedback from critic which describes that how well the agent is doing with respect to a fixed performance standard.\n",
    "    - Performance element: It is responsible for selecting external action\n",
    "    - Problem generator: This component is responsible for suggesting actions that will lead to new and informative experiences.\n",
    "- Hence, learning agents are able to learn, analyze performance, and look for new ways to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa68ae-ee89-47bc-b643-ff8800524c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
