{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda95cc9-cc9c-4d3c-b1d5-3918f5468b59",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\n",
    "\n",
    "### The KNN Algorithm\n",
    "1. Load the data\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "3. For each example in the data\n",
    "    - Calculate the distance between the query example and the current example from the data\n",
    "    - Add the distance and the index of the example to ordered collection\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "5. Pick the first K entries form the sorted collection\n",
    "6. Get the labels of the selected K entries\n",
    "7. If regresson, retrun the mean of the K labels\n",
    "8. If classfication, return the mode of the K labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f2fa350-8a1a-4d73-a97c-9eeaf119c33c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:20:53.273677Z",
     "iopub.status.busy": "2022-05-28T15:20:53.273375Z",
     "iopub.status.idle": "2022-05-28T15:20:53.276872Z",
     "shell.execute_reply": "2022-05-28T15:20:53.276203Z",
     "shell.execute_reply.started": "2022-05-28T15:20:53.273655Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fe4830-e280-45e1-a4f9-ae08c557094f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:12:01.418587Z",
     "iopub.status.busy": "2022-05-28T15:12:01.418074Z",
     "iopub.status.idle": "2022-05-28T15:12:01.421562Z",
     "shell.execute_reply": "2022-05-28T15:12:01.421037Z",
     "shell.execute_reply.started": "2022-05-28T15:12:01.418560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum(np.power((x1-x2), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b89b1eb-96ef-470d-bc6f-77cf006e4276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:02.247943Z",
     "iopub.status.busy": "2022-05-28T15:28:02.247426Z",
     "iopub.status.idle": "2022-05-28T15:28:02.252619Z",
     "shell.execute_reply": "2022-05-28T15:28:02.251970Z",
     "shell.execute_reply.started": "2022-05-28T15:28:02.247911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    K Nearest Neibors Algorithm python implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k: number of nearest neighbors\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predicted_labels = [self._predict(x) for x in X]\n",
    "        return np.array(predicted_labels)\n",
    "        \n",
    "    def _predict(self, x):\n",
    "        # compute distances\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # get k nearest samples, labels\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # majority vote, most common class label \n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e69fc8-6844-44ab-b711-f132c11e3afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:02.689933Z",
     "iopub.status.busy": "2022-05-28T15:28:02.689596Z",
     "iopub.status.idle": "2022-05-28T15:28:02.692759Z",
     "shell.execute_reply": "2022-05-28T15:28:02.692234Z",
     "shell.execute_reply.started": "2022-05-28T15:28:02.689916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a19735d1-7f76-4fe9-96b5-6a600a106fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:02.939774Z",
     "iopub.status.busy": "2022-05-28T15:28:02.939400Z",
     "iopub.status.idle": "2022-05-28T15:28:02.942581Z",
     "shell.execute_reply": "2022-05-28T15:28:02.942106Z",
     "shell.execute_reply.started": "2022-05-28T15:28:02.939756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5685ac7-3b81-4bc7-8112-120247dcd66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:03.140352Z",
     "iopub.status.busy": "2022-05-28T15:28:03.139827Z",
     "iopub.status.idle": "2022-05-28T15:28:03.143187Z",
     "shell.execute_reply": "2022-05-28T15:28:03.142659Z",
     "shell.execute_reply.started": "2022-05-28T15:28:03.140333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73ac0ad7-8a43-474d-bcba-1adb7a9d5e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:03.298129Z",
     "iopub.status.busy": "2022-05-28T15:28:03.297689Z",
     "iopub.status.idle": "2022-05-28T15:28:03.302910Z",
     "shell.execute_reply": "2022-05-28T15:28:03.302153Z",
     "shell.execute_reply.started": "2022-05-28T15:28:03.298110Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=530)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf9c1b10-0094-46f7-a78f-221e8a0231c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:03.625580Z",
     "iopub.status.busy": "2022-05-28T15:28:03.625181Z",
     "iopub.status.idle": "2022-05-28T15:28:03.628659Z",
     "shell.execute_reply": "2022-05-28T15:28:03.628076Z",
     "shell.execute_reply.started": "2022-05-28T15:28:03.625555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = KNN(k=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21ab0c8c-f34d-40be-9915-47b139a2ab5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T15:28:09.024145Z",
     "iopub.status.busy": "2022-05-28T15:28:09.023785Z",
     "iopub.status.idle": "2022-05-28T15:28:09.046845Z",
     "shell.execute_reply": "2022-05-28T15:28:09.046149Z",
     "shell.execute_reply.started": "2022-05-28T15:28:09.024127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classification accuracy 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(f\"KNN classification accuracy {accuracy(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b004562-20c6-46e5-801d-348ac200ba80",
   "metadata": {},
   "source": [
    "### Choosing the right value for K\n",
    "1. As we decrease the value of K to 1, our predictions become less stable. Less k will result less accuracy.\n",
    "2. Large value of k will generate a more stable result but if error labels are too much in the dataset, then the model become less reliable.\n",
    "3. Prefer to choose a number k with odd to avoid tie situation.\n",
    "\n",
    "### Advantages\n",
    "1. The algorithm is simple and easy to implement.\n",
    "2. There is no need to build a model, tune several parameters or make addtional assumptions.\n",
    "3. The algorithm is versatile. It can be used for classification, regression, and research.\n",
    "\n",
    "### Disadvantages\n",
    "1. The algorithm gets significantly slower as the number of examples and/or predictors/independent variables increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a291457-99d8-4253-9e97-586fbf880207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
